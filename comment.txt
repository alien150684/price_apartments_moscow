Артём, привет. Благодарю за ревью! Есть комментарии к твоим замечаниям.

- part1_airflow/dags/real_estate_prices.py 
Часть бибилиотек импортируется внутри функций-задач (task) на основании примеров из уроков. Импортирование на верхнем уровне может негативно сказаться на производительности планировщика. Соответствующая рекомендация дана здесь: https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html#top-level-python-codeirflow/stable/best-practices.html#top-level-python-code

- part1_airflow/dags/real_estate_prices_clean.py 
Ты пишешь, что "на этапе генерации фичей и препроцессинга имеется излишнее дробление". Мелкое дробление выполнено по рекомендации наставника Ивана Васильева. На семинаре по AirFlow он обосновывал это тем, что так проще выявлять ошибки в функциях-задачах DAG. Думаю, однозначного ответа на вопрос об оптимальной степени дробления не существует.

- part2_dvc/scripts/fit.py
"Есть рекомендация разнести валидацию и тренировку модели на отдельные этапы." Согласен в случае деления выборки на части: тренировочную и валидационную. Кросс-валидация и дальнейшее обучение модели производятся с использованием ВСЕЙ выборки. Если этапы кросс-валидации и обучения разместить в разных py-файлах, НЕОБХОДИМО ДУБЛИРОВАТЬ РЯД ШАГОВ: загрузки датасета, выделения обучающих признаков и целевой переменной, удаления из датасета незначимых признаков. Короче говоря, я следовал правилу: "Чем проще – тем лучше".

- part2_dvc/scripts/data.py
print с параметрами подключения к БД убрал. Это было твоё критическое замечание. С остальными замечаниями согласен, однако вносить существенные правки не стал с целью экономии времени.


